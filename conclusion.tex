\newpage
\section{Discussion and Conclusion}
	
Several conclusions can be made using the results of the previous chapter: 

\begin{itemize}
	\item The Hierarchical VMO Generator(HVG) works slower than company's solution without the first level cache
	\item The stability of HVG depends on the amount of transferred data: the less data, the more stable responses
	\item Without latency (that was introduced artificially) the HVG with an optimal configuration works roughly with the same speed as the current company solution where VMOs are generated on the client side
	\item With latency the HVG solution works faster 
\end{itemize}

The \cite{VarnApacheReverse} gives the detailed evaluation of Apache Traffic server and Varnish server; As a result, the comparison between them is omitted in this project. 

The HVG solution consumes more CPU and memory because it stores the graph of data model objects plus the fetched data from the content distributors. It uses computationally intensive breadth first search algorithm on the directed graph. On the other hand, the client side VMO generation sends multiple simple requests to the middleware server. They are light requests that consume small amount of CPU power and memory and are merely used for storing the final data model object.

Fortunately, the algorithm for generating HVG is executed rarely because most of the time the data is retrieved in the VMO cache. The drawback of this approach is that the data is stored two times: one as a part of Data Model Object, another as a part of View Model Object. The Data Model Object cache could be turned off, unfortunately this will give additional problems: if the VMO would be stored for the time equals of maximum TTL among all DMOs, some DMOs would become stale and the server response would be irrelevant. Taking this in consideration, the maximum TTL for VMO is computed as:

\begin{center}
	\begin{math}M = \min_{1 \leq i \leq N} D_{i},\{i=1:N\}\end{math}, N - amount of DMOs that need to be fetched in request.
\end{center}

Theoretically, the solution with HVG does not work well when the set of DMOs have TTL that dramatically differs from one another. In this case, the overhead produced by VMO computation will be greater than the latency for retrieving data model objects, but in general it requires additional study. 

\subsection{Further studies}

The Application Model Object (AMO) should be studied and corresponding conclusions should be produced. For small VMOs, perhaps, it would be more optimal to transfer compressed AMO.

The Web cache solution requires additional study in terms of selecting the appropriate algorithm for calculating TTL (time to live) of VMO/DMO objects. Currently, the TTL is set to the default time that was not selected through careful study. The maximum time for VMO equals the TTL of DMO that has minumum value. This is one of the proposed algorithms, however this question is not studied enough and requires futher work.

\newpage
